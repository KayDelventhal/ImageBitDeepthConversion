{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93108d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n250914init setup\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# file: train_8bit2hdr.py\n",
    "\n",
    "\"\"\"\n",
    "250914init setup\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67267a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. Imports\n",
    "# ============================================================\n",
    "import os\n",
    "# Make sure OpenCV can read EXR before importing cv2\n",
    "os.environ.setdefault(\"OPENCV_IO_ENABLE_OPENEXR\", \"1\")\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# 2. Utility functions\n",
    "# ============================================================\n",
    "from exr_to_ldr import srgb_to_linear, load_exr, tone_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6df0991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3. Dataset class\n",
    "# ============================================================\n",
    "class HDRDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Paired dataset:\n",
    "    - LDR: 8-bit (JPG/PNG) → linear float\n",
    "    - HDR: 32-bit EXR\n",
    "    \"\"\"\n",
    "    def __init__(self, ldr_folder, hdr_folder, transform=None, scale_hdr=4.0):\n",
    "        self.ldr_files = sorted(glob(os.path.join(ldr_folder, \"*\")))\n",
    "        self.hdr_files = sorted(glob(os.path.join(hdr_folder, \"*\")))\n",
    "        assert len(self.ldr_files) == len(self.hdr_files), \"Mismatch in dataset size!\"\n",
    "        self.transform = transform\n",
    "        self.scale_hdr = scale_hdr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ldr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # LDR → linear\n",
    "        ldr = cv2.imread(self.ldr_files[idx], cv2.IMREAD_COLOR)\n",
    "        ldr = cv2.cvtColor(ldr, cv2.COLOR_BGR2RGB) / 255.0\n",
    "        ldr = srgb_to_linear(ldr)\n",
    "\n",
    "        # HDR\n",
    "        hdr = load_exr(self.hdr_files[idx])\n",
    "        hdr = np.nan_to_num(hdr, nan=0.0, posinf=10.0, neginf=0.0)\n",
    "\n",
    "        # Normalize HDR by fixed scale\n",
    "        hdr = hdr / self.scale_hdr\n",
    "\n",
    "        # To tensors [C,H,W]\n",
    "        ldr = torch.from_numpy(ldr.transpose(2, 0, 1)).float()\n",
    "        hdr = torch.from_numpy(hdr.transpose(2, 0, 1)).float()\n",
    "\n",
    "        if self.transform:\n",
    "            ldr, hdr = self.transform(ldr, hdr)\n",
    "\n",
    "        return ldr, hdr\n",
    "\n",
    "# ============================================================\n",
    "# 4. HDRNet model\n",
    "# ============================================================\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=dilation, dilation=dilation)\n",
    "        self.bn1   = nn.BatchNorm2d(channels)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=dilation, dilation=dilation)\n",
    "        self.bn2   = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        return self.relu(out + x)\n",
    "\n",
    "class HDRNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, base_channels=64, num_resblocks=8):\n",
    "        super().__init__()\n",
    "        self.enc1 = nn.Conv2d(in_channels, base_channels, 3, stride=1, padding=1)\n",
    "        self.enc2 = nn.Conv2d(base_channels, base_channels*2, 3, stride=2, padding=1)\n",
    "        self.enc3 = nn.Conv2d(base_channels*2, base_channels*4, 3, stride=2, padding=1)\n",
    "\n",
    "        blocks = []\n",
    "        for i in range(num_resblocks):\n",
    "            dilation = 2 if i % 2 == 0 else 1\n",
    "            blocks.append(ResidualBlock(base_channels*4, dilation))\n",
    "        self.bottleneck = nn.Sequential(*blocks)\n",
    "\n",
    "        self.dec3 = nn.ConvTranspose2d(base_channels*4, base_channels*2, 4, stride=2, padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(base_channels*2, base_channels, 4, stride=2, padding=1)\n",
    "        self.dec1 = nn.Conv2d(base_channels, out_channels, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = F.relu(self.enc1(x))\n",
    "        e2 = F.relu(self.enc2(e1))\n",
    "        e3 = F.relu(self.enc3(e2))\n",
    "        b  = self.bottleneck(e3)\n",
    "        d3 = F.relu(self.dec3(b))\n",
    "        d2 = F.relu(self.dec2(d3))\n",
    "        out = self.dec1(d2)\n",
    "        return out  # linear HDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b0751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 6. Training\n",
    "# ============================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-4, device=\"cuda\", *,\n",
    "                 checkpoint_dir: str = \"./checkpoints\", resume_from: str | None = None,\n",
    "                 save_every: int = 1, save_best: bool = True):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    # Resume logic\n",
    "    if resume_from:\n",
    "        ckpt_path = resume_from\n",
    "        if resume_from in (\"latest\", \"best\"):\n",
    "            ckpt_path = get_latest_checkpoint(checkpoint_dir) if resume_from == \"latest\" else get_best_checkpoint(checkpoint_dir)\n",
    "        if ckpt_path and os.path.exists(ckpt_path):\n",
    "            data = load_checkpoint(model, optimizer, ckpt_path, map_location=device)\n",
    "            start_epoch = int(data.get(\"epoch\", 0)) + 1\n",
    "            best_val = float(data.get(\"val_loss\", best_val))\n",
    "            print(f\"Resumed from {ckpt_path} @ epoch {start_epoch} (best_val={best_val:.4f})\")\n",
    "        else:\n",
    "            print(f\"No checkpoint found for resume_from={resume_from}; starting fresh.\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for ldr, hdr in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\"):\n",
    "            ldr, hdr = ldr.to(device), hdr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(ldr)\n",
    "            loss = hdr_loss(pred, hdr)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= max(1, len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for ldr, hdr in val_loader:\n",
    "                ldr, hdr = ldr.to(device), hdr.to(device)\n",
    "                pred = model(ldr)\n",
    "                val_loss += hdr_loss(pred, hdr).item()\n",
    "        val_loss /= max(1, len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train {train_loss:.4f} | Val {val_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoints\n",
    "        should_save = ((epoch + 1) % save_every == 0)\n",
    "        if should_save:\n",
    "            path = save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_dir, tag=f\"e{epoch+1:03d}\")\n",
    "            print(\"Saved checkpoint:\", path)\n",
    "        if save_best and val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            path = save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_dir, tag=\"best\")\n",
    "            print(\"Updated best checkpoint:\", path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ea9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. Inference (testing)\n",
    "# ============================================================\n",
    "def test_model(model, test_loader, device=\"cuda\", save_folder=\"results\"):\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (ldr, _) in enumerate(test_loader):\n",
    "            ldr = ldr.to(device)\n",
    "            pred = model(ldr).cpu().numpy()\n",
    "            pred = np.clip(pred * 4.0, 0, None)   # undo HDR scale\n",
    "            pred = pred.transpose(0, 2, 3, 1)     # [B,H,W,C]\n",
    "            for j in range(pred.shape[0]):\n",
    "                out_path = os.path.join(save_folder, f\"test_{i}_{j}.exr\")\n",
    "                imageio.imwrite(out_path, pred[j].astype(np.float32), format=\"EXR\")\n",
    "                print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157bbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. Checkpoint utilities\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure_dir(p: str | Path) -> Path:\n",
    "    p = Path(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_dir=\"./checkpoints\", tag=None):\n",
    "    checkpoint_dir = ensure_dir(checkpoint_dir)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tag = tag or f\"e{epoch:03d}\"\n",
    "    ckpt_path = checkpoint_dir / f\"ckpt_{tag}_{ts}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"train_loss\": float(train_loss),\n",
    "        \"val_loss\": float(val_loss),\n",
    "        \"timestamp\": ts,\n",
    "    }, ckpt_path)\n",
    "    # also update symlinks/files for convenience\n",
    "    latest_path = checkpoint_dir / \"latest.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"train_loss\": float(train_loss),\n",
    "        \"val_loss\": float(val_loss),\n",
    "        \"timestamp\": ts,\n",
    "    }, latest_path)\n",
    "    return str(ckpt_path)\n",
    "\n",
    "def load_checkpoint(model, optimizer=None, checkpoint_path: str | Path = \"./checkpoints/latest.pt\", map_location=None):\n",
    "    checkpoint_path = str(checkpoint_path)\n",
    "    data = torch.load(checkpoint_path, map_location=map_location)\n",
    "    model.load_state_dict(data[\"model_state\"])\n",
    "    if optimizer is not None and \"optimizer_state\" in data:\n",
    "        optimizer.load_state_dict(data[\"optimizer_state\"])\n",
    "    return data\n",
    "\n",
    "def list_checkpoints(checkpoint_dir=\"./checkpoints\"):\n",
    "    p = Path(checkpoint_dir)\n",
    "    files = sorted(p.glob(\"ckpt_*.pt\"))\n",
    "    return [str(f) for f in files]\n",
    "\n",
    "def get_latest_checkpoint(checkpoint_dir=\"./checkpoints\"):\n",
    "    p = Path(checkpoint_dir)\n",
    "    latest = p / \"latest.pt\"\n",
    "    return str(latest) if latest.exists() else None\n",
    "\n",
    "def get_best_checkpoint(checkpoint_dir=\"./checkpoints\"):\n",
    "    # choose the ckpt with lowest recorded val_loss\n",
    "    p = Path(checkpoint_dir)\n",
    "    best_path, best_val = None, float(\"inf\")\n",
    "    for f in p.glob(\"ckpt_*.pt\"):\n",
    "        try:\n",
    "            d = torch.load(f, map_location=\"cpu\")\n",
    "            v = float(d.get(\"val_loss\", float(\"inf\")))\n",
    "            if v < best_val:\n",
    "                best_val, best_path = v, f\n",
    "        except Exception:\n",
    "            pass\n",
    "    return str(best_path) if best_path else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c64bbdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: 68\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180203.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180203.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180301.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180301.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180402.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180402.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180501.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180501.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180701.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180701.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180802.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180802.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00180901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181001.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181001.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181301.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181301.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181401.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181401.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181501.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181501.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181699.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181699.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181801.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181801.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181899.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00181899.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182401.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182401.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182502.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182502.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182802.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182802.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00182901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183101.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183202.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP02.00183202.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000030.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000030.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000098.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000098.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000900.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00000900.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00001901.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002600.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002700.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002800.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002900.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00002900.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003000.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003100.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003200.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003300.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003400.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003500.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003601.png\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003700.png\n",
      "files: 4\n",
      "Saved: ./data/train/ldr\\Mozart_TEST_EP04.00003700.png\n",
      "files: 4\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP02.00181201.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP02.00181201.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP02.00182101.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP02.00182101.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP04.00001400.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP04.00001400.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP04.00002200.png\n",
      "Saved: ./data/test/ldr\\Mozart_TEST_EP04.00002200.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9. Example usage\n",
    "# ============================================================\n",
    "# # Batch convert EXR → LDR (png)\n",
    "from exr_to_ldr import batch_convert\n",
    "\n",
    "train_ldr_folder = \"./data/train/ldr\"\n",
    "train_hdr_folder = \"./data/train/hdr\"\n",
    "os.makedirs(train_ldr_folder, exist_ok=True)\n",
    "os.makedirs(train_hdr_folder, exist_ok=True)\n",
    "\n",
    "test_ldr_folder = \"./data/test/ldr\"\n",
    "test_hdr_folder = \"./data/test/hdr\"\n",
    "os.makedirs(test_ldr_folder, exist_ok=True)\n",
    "os.makedirs(test_hdr_folder, exist_ok=True)\n",
    "\n",
    "batch_convert(train_hdr_folder, train_ldr_folder, fmt=\"png\", exposure=1.0)\n",
    "batch_convert(test_hdr_folder, test_ldr_folder, fmt=\"png\", exposure=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1176326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from folder every n (e.g 100th) image into other folder\n",
    "input_folder = r\"E:\\20241219_KAI_Exports\\Mozart_TEST_EP02\".replace(\"\\\\\", \"/\")\n",
    "input_folder = r\"E:\\20241219_KAI_Exports\\Mozart_TEST_EP04\".replace(\"\\\\\", \"/\")\n",
    "output_folder = r\"C:\\Users\\vfx\\OneDrive\\_Python_\\DEV\\ImageBitDeepthConversion\\data\\train\\hdr\".replace(\"\\\\\", \"/\")\n",
    "import shutil\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "n = 100  # copy every 100th image\n",
    "for i, filename in enumerate(os.listdir(input_folder)):\n",
    "    if i % n == 0:\n",
    "        shutil.copy(os.path.join(input_folder, filename), output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384843ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move random 10% of files from input_folder to output_folder\n",
    "import random\n",
    "import shutil\n",
    "input_folder = r\"C:\\Users\\vfx\\OneDrive\\_Python_\\DEV\\ImageBitDeepthConversion\\data\\train\\hdr\".replace(\"\\\\\", \"/\")\n",
    "output_folder = r\"C:\\Users\\vfx\\OneDrive\\_Python_\\DEV\\ImageBitDeepthConversion\\data\\test\\hdr\".replace(\"\\\\\", \"/\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "n = 10  # 10%\n",
    "all_files = os.listdir(input_folder)\n",
    "num_to_copy = max(1, len(all_files) // n)\n",
    "files_to_copy = random.sample(all_files, num_to_copy)\n",
    "for filename in files_to_copy:\n",
    "    shutil.move(os.path.join(input_folder, filename), output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. List available checkpoints\n",
    "# ============================================================\n",
    "\n",
    "def show_checkpoints(checkpoint_dir=\"./checkpoints\"):\n",
    "    files = list_checkpoints(checkpoint_dir)\n",
    "    print(f\"Found {len(files)} checkpoints in {checkpoint_dir}\")\n",
    "    for f in files:\n",
    "        try:\n",
    "            d = torch.load(f, map_location=\"cpu\")\n",
    "            print(f\"- {Path(f).name}: epoch={d.get('epoch')}, val={d.get('val_loss')} ts={d.get('timestamp')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"- {Path(f).name}: (unreadable) {e}\")\n",
    "\n",
    "show_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1ad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|██████████| 1/1 [01:54<00:00, 114.27s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train nan | Val 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|██████████| 1/1 [01:55<00:00, 115.87s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train 0.1117 | Val 0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|██████████| 1/1 [01:48<00:00, 108.78s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train 0.0751 | Val 0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train]: 100%|██████████| 1/1 [01:57<00:00, 117.12s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train 0.0562 | Val 0.1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train]: 100%|██████████| 1/1 [01:57<00:00, 117.72s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train 0.0454 | Val 0.0999\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 10. Example usage\n",
    "# ============================================================\n",
    "def run_training(ldr_folder, hdr_folder)\n",
    "    dataset = HDRDataset(ldr_folder, hdr_folder)\n",
    "    n = len(dataset)\n",
    "    train_size = int(0.8 * n)\n",
    "    val_size   = n - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # On Windows/Jupyter, use single-process loading to avoid worker crashes\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = HDRNet()\n",
    "\n",
    "    model = train_model(model, train_loader, val_loader, epochs=5, device=device)\n",
    "\n",
    "    test_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "    test_model(model, test_loader, device=device)\n",
    "    \n",
    "# Example: resume from latest checkpoint and continue 2 epochs\n",
    "model = HDRNet()\n",
    "ldr_folder = \"./data/ldr\"\n",
    "hdr_folder = \"./data/hdr\"\n",
    "\n",
    "dataset = HDRDataset(ldr_folder, hdr_folder)\n",
    "n = len(dataset)\n",
    "train_size = int(0.8 * n)\n",
    "val_size   = n - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"CUDA or CPU ? - Device: {device}\")\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, epochs=2, device=device,\n",
    "                    checkpoint_dir=\"./checkpoints\", resume_from=\"latest\", save_every=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
